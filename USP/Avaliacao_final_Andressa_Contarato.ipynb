{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Ci√™ncias de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Professor: Francisco Rodrigues\n",
    "##### Aluna: Andressa Contarato Rodrigues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O desenvolvimento desse projeto se dar√° atrav√©s dos seguintes passos:\n",
    "    \n",
    "    * Pr√©-processamento\n",
    "    \n",
    "    1- Formula√ß√£o do problema e preparo dos dados\n",
    "    2 - Limpeza e normaliza√ß√£o dos dados\n",
    "    3- Transforma√ß√£o para valores num√©ricos (one-hot-encoding) se precisar.\n",
    "    \n",
    "    * Classifica√ß√£o (classificar de acordo com a qualidade)\n",
    "    \n",
    "    4 - kvizinhos (encontre o melhor k usando valida√ß√£o cruzada)\n",
    "    5 - √Årvore de decis√£o\n",
    "    6 - Naive Bayes\n",
    "    7 - SVM (encontre o melhor C usando valida√ß√£o cruzada)\n",
    "    8 - Random Forest (encontre o melhor n√∫mero de estimadores usando valida√ß√£o cruzada)\n",
    "    \n",
    "    * Ordena√ß√£o dos atributos\n",
    "    \n",
    "    9 - Para o algoritmo random forest, mostre a import√¢ncia de cada atributo.\n",
    "    \n",
    "    * Regress√£o\n",
    "    \n",
    "    10 - Usando regress√£o linear, tente predizer a porcentagem de √°lcool.\n",
    "    11 - Compare os m√©todos Lasso, Ridge Regression, calculando o erro quadr√°tico m√©dio em fun√ß√£o dos seus par√¢metros (alpha).\n",
    "    \n",
    "    * Conclus√£o\n",
    "    \n",
    "    12 - Discuss√£o dos resultados obtidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow\"> Objetivo: Vamos considerar o problema de classifica√ß√£o dos de vinhos dispon√≠vel no portal Kaggle (link: https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009).\n",
    "Ou seja, objetivamos construir um projeto para classificar os dados, de modo a verificar o qu√£o preciso s√£o nossos resultados comparados com solu√ß√µes de outros usu√°rios. \n",
    "Vamos mostrar todas as fases do projeto e os resultados, mas lembramos que essa √© uma poss√≠vel solu√ß√£o. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso objetivo √© classificar o vinho de acordo com a qualidade dele e predizer o teor alc√≥olico deste vinho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula√ß√£o do problema e leitura dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos considerar a base de dados de vinhos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos contidos nos dados\n",
    "\n",
    "1 - fixed acidity: a maioria dos √°cidos envolvidos no vinho ou fixa ou n√£o vol√°til (n√£o evapore rapidamente) \n",
    "\n",
    "2 - volatile acidity: a quantidade de √°cido ac√©tico no vinho, que em n√≠veis muito altos pode levar a um sabor desagrad√°vel ao vinagre \n",
    "\n",
    "3 - citric acid: encontrado em pequenas quantidades, o √°cido c√≠trico pode adicionar 'frescura' e sabor aos vinhos\n",
    "\n",
    "4 - residual sugar: a quantidade de a√ß√∫car restante ap√≥s o t√©rmino da fermenta√ß√£o, √© raro encontrar vinhos com menos de 1 grama / litro e vinhos com mais de 45 gramas / litro s√£o considerados doces \n",
    "\n",
    "5 - chlorides: a quantidade de sal no vinho \n",
    "\n",
    "6 - free sulfur dioxide: a forma livre de SO2 existe em equil√≠brio entre o SO2 molecular (como um g√°s dissolvido) e o √≠on bissulfito; impede o crescimento microbiano e a oxida√ß√£o do vinho \n",
    "\n",
    "7 - total sulfur dioxide: formas livres e ligadas de S02; em baixas concentra√ß√µes, o SO2 √© principalmente indetect√°vel no vinho, mas em concentra√ß√µes livres de SO2 acima de 50 ppm, o SO2 se torna evidente no nariz e no sabor do vinho \n",
    "\n",
    "8 - density: a densidade da √°gua no vinho √© pr√≥xima √† da √°gua, dependendo da porcentagem de teor de √°lcool e a√ß√∫car \n",
    "\n",
    "9 - pH: descreve como um vinho √© √°cido ou b√°sico em uma escala de 0 (muito √°cido) a 14 (muito b√°sico); a maioria dos vinhos tem entre 3-4 na escala de pH \n",
    "\n",
    "10 - sulphates: um aditivo de vinho que pode contribuir para os n√≠veis de g√°s di√≥xido de enxofre (S02), que atua como antimicrobiano e antioxidante \n",
    "\n",
    "11 - alcohol: a percentagem de √°lcool do vinho \n",
    "\n",
    "12 - quality: vari√°vel de sa√≠da de qualidade (com base em dados sensoriais, pontua√ß√£o entre 0 e 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando os pacotes necess√°rios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dentro da linguagem pandas ha v√°rios m√©todos e fun√ß√µes pr√©-definidas, por√©m muitas das quais vamos utilizar aqui, \n",
    "# temos que 'chamar' atrav√©s de uma estrutura import ou se for um m√≥dulo \n",
    "# de uma biblioteca, atrav√©s do from.\n",
    "\n",
    "import matplotlib.pyplot as plt # m√≥dulo matplotlib para construcao de graficos\n",
    "import numpy as np # biblioteca pandas usada para manipula√ß√£o de dados, tb da forma big data e constru√ß√£o de m√©tricas\n",
    "import os # biblioteca python para setar egerenciar arquivos localmente\n",
    "import pandas as pd # biblioteca Pandas √© usada para manipula√ß√£o de dados\n",
    "import random # m√≥dulo do Numpy de gera√ß√£o de n√∫meros randomicos\n",
    "from sklearn.preprocessing import StandardScaler # m√≥dulo do sklearn para padroniza√ß√£o dos dados do sklearn para padronizacao e normalizacao dos dados\n",
    "from sklearn.model_selection import train_test_split # m√≥dulo do sklearn para separar dados de teste e de treino\n",
    "from sklearn.model_selection import cross_validate # m√≥dulo sklearn para valida√ß√£o cruzada\n",
    "from sklearn.neighbors import KNeighborsClassifier # m√≥dulo sklearn para calcular o modelo de machine learning knn\n",
    "from sklearn import tree # importando o m√≥dulo do sklearn do modelo de √°rvore de decis√£o\n",
    "from sklearn.metrics import accuracy_score # para calculo da acur√°cia em m√≥dulos que nao se tem implementados\n",
    "from sklearn import tree # importando m√≥dulo de visualiza√ß√£o da √°rvore\n",
    "from sklearn.naive_bayes import GaussianNB # m√≥dulo do sklearn para implementa√ß√£o do modelo de Naive Bayes com distribui√ß√£o normal\n",
    "from sklearn import metrics # m√≥dulo do sklearn para computa√ß√£o de m√©tricas dentro do modelo de naive bayes\n",
    "from sklearn.naive_bayes import BernoulliNB # m√≥dulo do sklearn para implementa√ß√£o do modelo de Naive Bayes com distribui√ß√£o bernoulli\n",
    "from sklearn.ensemble import RandomForestClassifier # m√≥dulo do sklearn para constru√ß√£o do modelo de Random Forest\n",
    "from sklearn.linear_model import LinearRegression # m√≥dulo sklearn para regressao linear\n",
    "from sklearn.decomposition import PCA # m√≥dulo sklearn para constru√ß√£o da pca\n",
    "from sklearn.model_selection import train_test_split # m√≥dulo sklearn para construcao do split para dataset de teste e de treino num modelo de regressao linear\n",
    "from sklearn.linear_model import Lasso # m√≥dulo sklearn para importacao da m√©trica de lasso\n",
    "from sklearn.metrics import mean_squared_error # m√≥dulo sklear para importacao da estatistica de teste erro quadr√°tico m√©dio\n",
    "from sklearn.metrics import r2_score # m√≥dulo sklear para importacao da estatistica de teste R2\n",
    "from sklearn.linear_model import Ridge, RidgeCV # m√≥dulo sklearn para importacao da m√©trica de ridge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Formula√ß√£o do problema e preparo dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42) # define a semente (importante para reproduzir os resultados)\n",
    "\n",
    "dir_file = '' # insira o diret√≥rio onde se encontra o dataset\n",
    "# ex.: /home/andressa/Desktop/\n",
    "# criando um objeto do meu diretorio do dataset\n",
    "os.chdir(dir_file) # setando aonde meu dataset est√°\n",
    "df = pd.read_csv('winequality-red.csv') # importando os dados\n",
    "\n",
    "print(\"N√∫mero de linhas e colunas no dataset:\", df.shape) # funcao de printar\n",
    "attributes = list(df.columns) # construindo um objeto tipo lista para armazenar os nomes das variaveis\n",
    "features_names = df.columns\n",
    "df.head(10) # funcao head para mostrar uma amostra do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a classifica√ß√£o h√° resultados melhores, quanto a acur√°cia dos modelos, o que ser√° apresentado s√£o os resultados do modelo com uma constru√ß√£o de uma nova target que seja categ√≥rica e dicot√¥mica. \n",
    "\n",
    "Todavia, h√° tamb√©m escrito a compara√ß√£o entre modelos usando a vari√°vel original quality como target e a vari√°vel qualidade criada. \n",
    "\n",
    "A vari√°vel qualidade receber√° 1 se o vinho for classificado com uma nota maior ou igual a 6 e 0 caso contr√°rio, considerando a m√©dia da qualidade dos vinhos descrito na an√°lise descritiva acima e arredondando uma casa decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando uma variavel categorica\n",
    "\n",
    "qualidade = []\n",
    "for i in range(0,df.shape[0]):\n",
    "    if df.iloc[i,11] < 6:\n",
    "        qualidade.append(0)\n",
    "    else:\n",
    "        qualidade.append(1)\n",
    "df['qualidade'] = qualidade\n",
    "df.head()\n",
    "\n",
    "df = df.drop(['quality'], axis=1) # removendo a coluna quality\n",
    "\n",
    "# Obs: se for analisar a quality, nao rodar esta c√©lula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Limpeza e normaliza√ß√£o dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados pode apresentar valores nulos (not a number: nan). A sua identifica√ß√£o pode ser feita usando m√©todos da biblioteca Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False).head(10)# verifica√ß√£o se h√° valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado mostrou que n√£o h√° valores faltantes na base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() # reomo√ß√£o de valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√£o apresenta nenhum valor faltante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna True na posi√ß√£o em que h√° uma linha duplicada\n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apresenta valor duplicado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove as linhas duplicadas\n",
    "df = df.drop_duplicates()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso o tamanho da base de dados tamb√©m se altera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar se as classes est√£o balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df[df.columns[-1]] # considerando quality original do dataset\n",
    "# classes = df[df.columns[-2]]\n",
    "cl = np.unique(classes)\n",
    "ncl = np.zeros(len(cl))\n",
    "for i in np.arange(0, len(cl)):\n",
    "    a = classes == cl[i]\n",
    "    ncl[i] = len(classes[a])\n",
    "    \n",
    "numbers = np.arange(0, len(cl))\n",
    "plt.bar(numbers, ncl,  alpha=.75)\n",
    "plt.xticks(numbers, cl)\n",
    "plt.title('N√∫mero de elementos em cada classe')\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a vari√°vel quality original: H√° mais vinhos classificados como 5 e 6, tendo um desbalanceamento dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a vari√°vel qualidade criada: h√° um melhor balanceamento considerando vinhos classificados maior ou igual a 6 como bons (atributo 1) e 0 caso contr√°rio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An√°lise Descritiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos valores muito discrepantes entre as variaveis, vide o maximo da total sulfur dioxide com a density. E, na vari√°vel tamb√©m, vide a total sulfur dioxide novamente. Necessitando de uma normaliza√ß√£o dos dados.\n",
    "Em m√©dia, a pontua√ß√£o do vinho √© de boa qualidade (considerando acima de 4 bom).\n",
    "A varia√ß√£o da quality √© muito pequena e a varia√ß√£o do total sulfur dioxide √© uma das maiores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertemos em formato numpy para facilitar a manipulacao dos dados\n",
    "data = df.to_numpy() # dataframe do pandas para array numpy\n",
    "nrow,ncol = data.shape # atribuindo aos objetos nrow e ncol o tamanho do conjunto de dados\n",
    "\n",
    "y = data[:,-1] # considerando quality\n",
    "# X = data[:,0:ncol-2] # construindo o dataset de analise sem a variavel target\n",
    "# retirando a quality para analisar a qualidade como y, variavel target\n",
    "\n",
    "X = data[:,0:ncol-1]\n",
    "\n",
    "print('Dados originais:') # mostrando a m√©dia e desvio padrao dos atributos do conjunto de dados X ja transformados\n",
    "print('Media: ', np.mean(X, axis = 0))\n",
    "print('Desvio Padrao:', np.std(X, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normaliza√ß√£o dos dados de forma a evitar problemas de escala nos atributos\n",
    "scaler = StandardScaler().fit(X) # normaliza√ß√£o dos dados\n",
    "X = scaler.transform(X) # tranforma√ß√£o dos dados\n",
    "\n",
    "print('Dados transformados:') # mostrando a m√©dia e desvio padrao dos atributos do conjunto de dados X ja transformados\n",
    "print('Media: ', np.mean(X, axis = 0))\n",
    "print('Desvio Padrao:', np.std(X, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados aqui ficaram numa escala variando de -8 at√© 4 aproximadamente (arredondando). Mas a distancia entre eles ficou menor comparado com o dataset original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ter uma ideia da separa√ß√£o entre as classes realizando a proje√ß√£o dos atributos em duas dimens√µes usando PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(X)\n",
    "\n",
    "classes = np.unique(y)\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "aux = 0\n",
    "plt.figure(figsize=(8,5))\n",
    "for c in classes:\n",
    "    if c == 1:\n",
    "        lb = 'Bom'\n",
    "    else:\n",
    "        lb = 'Ruim'\n",
    "    nodes = np.where(y == c)\n",
    "    plt.scatter(pca_result[nodes,0], pca_result[nodes,1], s=50, color = colors[aux], label = lb)\n",
    "    aux = aux + 1\n",
    "plt.legend()\n",
    "plt.xlabel(\"First component\", fontsize=20)\n",
    "plt.ylabel(\"Second component\", fontsize=20)\n",
    "plt.xticks(color='k', size=20)\n",
    "plt.yticks(color='k', size=20)\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando a vari√°vel original quality: temos que o gr√°fico apresentou uma n√£o separa√ß√£o dos dados e 7 classifica√ß√µes diferentes. \n",
    "\n",
    "Considerando a vari√°vel criada qualidade: temos que em duas dimens√µes, a separa√ß√£o n√£o √© clara, por√©m uma hip√≥teses √© que seja mais f√°cil de se determinar a sa√≠da com um menor n√∫mero de classes e distanciando mais as caracter√≠sticas.\n",
    "\n",
    "Al√©m disso, podemos identificar os atributos que mais explicam a vari√¢ncia nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(X)\n",
    "var_exp = pca.explained_variance_ratio_\n",
    "\n",
    "importances = var_exp\n",
    "attributes = df.columns[1:len(df.iloc[:,0:df.shape[0]-1].columns)] # considerando quality\n",
    "indices = np.argsort(importances)\n",
    "attributes_rank = []\n",
    "for i in indices:\n",
    "    attributes_rank.append(attributes[i])\n",
    "plt.title('Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), attributes_rank, fontsize=25)\n",
    "plt.xlabel('Relative Importance',fontsize=25)\n",
    "plt.xticks(color='k', size=20)\n",
    "plt.yticks(color='k', size=20)\n",
    "plt.xlim([0.0, 0.25])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando a vari√°vel quality original: tem-se a seguinte an√°lise: as classes maiores (classificando o vinho como bom) est√£o mais relacionadas as vari√°veis: volatile acidity, citric acid e residual sugar.\n",
    "\n",
    "\n",
    "Considerando a vari√°vel criada, qualidade: a classe cujo o vinho √© classificado como bom (maior ou igual a 6), est√° intimamente relacionado mais com os atributos volatile acidity, citric acid e residual sugar. Logo, podemos considerar apenas os atributos mais importantes na classifica√ß√£o. No entanto, vamos inicialmente manter esses atributos em nossos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos verificar como a vari√¢ncia muda de acordo com o n√∫mero de componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X)\n",
    "plt.figure(figsize=(8,5))\n",
    "ncomp = np.arange(1, np.shape(X)[1]+1)\n",
    "plt.plot(ncomp, np.cumsum(pca.explained_variance_ratio_), 'ro-')\n",
    "plt.xlabel('number of components', fontsize=20)\n",
    "plt.ylabel('cumulative explained variance', fontsize=20);\n",
    "plt.xticks(color='k', size=20)\n",
    "plt.yticks(color='k', size=20)\n",
    "plt.grid(True)\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que com 7 componentes explicamos cerca de 90% dos dados. No entanto, como o n√∫mero de atributos n√£o √© elevado, vamos considerar os dados sem sele√ß√£o dos atributos principais, ou seja, os dados sem usar a proje√ß√£o. (Mesma an√°lise considerando a vari√°vel quality original e a vari√°vel qualidade criada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos tamb√©m analisar o n√≠vel de correla√ß√£o nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "#Plot Correlation Matrix using Matplotlib\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(corr, cmap='Blues', interpolation='none', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr)), corr.columns, rotation='vertical')\n",
    "plt.yticks(range(len(corr)), corr.columns);\n",
    "plt.suptitle('Correlation between variables', fontsize=15, fontweight='bold')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que as vari√°veis mais correlacionadas s√£o:\n",
    "\n",
    "volatile acidity x citric acid\n",
    "\n",
    "density x fixed acidity\n",
    "\n",
    "(Mesma an√°lise considerando a vari√°vel quality original e a vari√°vel qualidade criada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Transforma√ß√£o para valores num√©ricos (one-hot-encoding) se precisar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados aqui s√£o todos num√©ricos, n√£o fazendo necess√°ria esta etapa de one-hot-enconding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para treinar o classificador, precisamos dividir o dataset em conjunto de teste e de treino\n",
    "\n",
    "p = 0.3 # fracao de elementos no conjunto de teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = p, random_state = 42) # dividindo o dataset em teste e treino, de acordo com p que √© a porcentagem de dados que quero ter em cada dataset\n",
    "# no caso, definimos 0.3 para teste o 0.7 para treino\n",
    "# A partir desse conjunto de dados, podemos realizar a classifica√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi separado 30% para dados de teste e 70% para dados de treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - kvizinhos (encontre o melhor k usando valida√ß√£o cruzada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro m√©todo usado aqui para classifica√ß√£o ser√° o m√©todo dos vizinhos mais p√≥ximos, ou knn. O knn √© baseado no conceito de dist√¢ncia entre atributos. Para realizar a classifica√ß√£o, vamos usar a biblioteca scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nkf = 10 # n√∫mero de folds\n",
    "vk = [] # armazena os valores de k, cria√ß√£o de lista nula\n",
    "vscore = [] # armazena a m√©dia do test score, cria√ß√£o de lista nula\n",
    "for k in range(1, 20):\n",
    "    model = KNeighborsClassifier(n_neighbors=k, metric = 'euclidean') # modelo knn considerando a distancia euclidiana com o argumento metric = 'euclidian'\n",
    "    cv = cross_validate(model, x_train, y_train, cv=nkf) # realiza a valida√ß√£o cruzada\n",
    "    print('k:', k, 'accurace:', cv['test_score'].mean()) # mostra a k-√©sima acur√°cia do k-√©simo modelo\n",
    "    vscore.append(cv['test_score'].mean()) # armazena o resultado numa lista\n",
    "    vk.append(k) # armazenando o valor de k vizinhos na lista e populando a lista que antes era uma lista nula\n",
    "\n",
    "plt.plot(vk, vscore, '-bo') # fun√ß√£o de se construir um ambiente para plotar o gr√°fico\n",
    "plt.xlabel('k', fontsize = 15) # definindo o eixo x\n",
    "plt.ylabel('Accuracy', fontsize = 15) # definindo o eixo y\n",
    "plt.show(True) # plotando\n",
    "best_k = np.argmax(vscore)+1 # mostrando o melhor k com o argumento argmax dentro da lista criada\n",
    "print('Melhor k:', best_k) # mostrando o resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a vari√°vel original quality: O melhor k foi k=1 com uma acur√°cia de 0.6239480807086614, arrendondando para uma casa decimal, temos acur√°cia igual a 0.6 \n",
    "\n",
    "Modelo considerando a vari√°vel criada qualidade: o melhor k foi 8 com uma acur√°cia de 0.7401973684210527 ou 0.7 (arredondando)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - √Årvore de decis√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterio de gini\n",
    "model = tree.DecisionTreeClassifier(criterion = 'gini', random_state = 101) # Cria o modelo usando o criterio Gini\n",
    "model.fit(x_train,y_train) # Ajusta o modelo usando os dados de treinamento\n",
    "y_pred = model.predict(x_test) # realizar a predi√ß√£o\n",
    "score = accuracy_score(y_pred, y_test) # calcula a acuracia\n",
    "print('Accuracy:', score) # mostrando a acur√°cia do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a vari√°vel quality: A acur√°cia do modelo de √°rvore de decis√£o considerando o criterio de gini, resultou numa acur√°cia de 0.58125, arredondando, temos uma acur√°cia de 0.6 (arredondando). Ainda, neste modelo, houve uma arvore muito grande e confusa por haver mais possibilidades de classifica√ß√£o, tendo uma an√°lise gr√°fica mais complexa.\n",
    "\n",
    "Modelo considerando a vari√°vel qualidade: usando o crit√©rio de gini temos a acur√°cia de 0.6642156862745098 ou 0.7 (arredondando). A √°rvore ficou mais simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(x_train,y_train) # modelo de arvore de decisao\n",
    "plt.figure(figsize=(15,10)) # plotando a figura\n",
    "tree.plot_tree(model, filled = True) # estrutura da figura\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando a medida de entropia\n",
    "model = tree.DecisionTreeClassifier(criterion = 'entropy',random_state = 101)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) \n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a vari√°vel quality: a acur√°cia do modelo de √°rvore de decis√£o considerando o criterio de entropia, resultou numa acur√°cia de 0.578125, arredondando, temos uma acur√°cia de 0.6 (arredondando). Ainda, neste modelo, houve uma arvore muito grande e confusa por haver mais possibilidades de classifica√ß√£o, tendo uma an√°lise gr√°fica mais complexa.\n",
    "\n",
    "Modelo considerando a vari√°vel qualidade: usando o crit√©rio de entropia temos a acur√°cia de 0.6421568627450981 ou 0.6 (arredondando). Aqui se obteve uma √°rvore mais simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(x_train,y_train) # modelo de arvore de decisao\n",
    "plt.figure(figsize=(15,10)) # plotando a figura\n",
    "tree.plot_tree(model, filled = True) # estrutura da figura\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limitando o tamanho da arvore\n",
    "model = tree.DecisionTreeClassifier(criterion = 'gini', max_depth = 2, random_state = 101) # cria o modelo com n√∫mero m√°ximo de n√≠veis max_depth\n",
    "model.fit(x_train,y_train) # ajusta aos dados de treinamento\n",
    "y_pred = model.predict(x_test) # faz a predi√ß√£o usando os dados de teste\n",
    "score = accuracy_score(y_pred, y_test) # calcula a acur√°cia\n",
    "print('Accuracy:', score) # mostra o resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limitando o tamanho da arvore\n",
    "model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 2, random_state = 101) # cria o modelo com n√∫mero m√°ximo de n√≠veis max_depth\n",
    "model.fit(x_train,y_train) # ajusta aos dados de treinamento\n",
    "y_pred = model.predict(x_test) # faz a predi√ß√£o usando os dados de teste\n",
    "score = accuracy_score(y_pred, y_test) # calcula a acur√°cia\n",
    "print('Accuracy:', score) # mostra o resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerndo a vari√°vel original quality: O melhor modelo √© da √°rvore de decis√£o usando o crit√©rio de gini, se considerarmos todas as casas decimais, caso contr√°rio os dois modelos s√£o bons. Limitando os dados, temos um decr√©scimo na acur√°cia considerando tanto o modelo de gini quanto de entropia, ambos cairam para uma acur√°cia de 0.53125, ou 0.5. Utilizando a √°rvore de decis√£o completa, temos que a √°rvore com o crit√©rio de entropia apresenta um distribui√ß√£o maior num ramo s√≥ da √°rvore, enquanto considerando o criterio de gini, a distribui√ß√£o dos ramos s√£o praticamente homogeneas. \n",
    "\n",
    "Modelo considerando a vari√°vel criada qualidade: considerando o crit√©rio de gini temos 0.678921568627451 ou 0.7 (arredondando) e considerando a entropia temos 0.6715686274509803 ou 0.7 (arredondando)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No classificador Naive Bayes, podemos assumir que os atributos s√£o normalmente distribu√≠dos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print('Accuracy: ', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a vari√°vel original quality: A acur√°cia do modelo de naive bayes considerando os dados com uma distribui√ß√£o de Normal, resultou numa acur√°cia de 0.5375, arredondando, temos uma acur√°cia de 0.5.\n",
    "\n",
    "Modelo considerando a vari√°vel criada qualidade: a acur√°cia foi de 0.75 ou 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra maneira de efetuarmos a classifica√ß√£o √© assumirmos que os atributos possuem distribui√ß√£o diferente da normal. Uma possibilidade √© assumirmos que os dados possuem distribui√ß√£o de Bernoulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos a fun√ß√£o BernoulliNB para realizar a classifica√ß√£o usando a distribui√ß√£o de Bernoulli\n",
    "model = BernoulliNB() # modelo considerando os dados com distribui√ß√£o de bernoulli\n",
    "model.fit(x_train, y_train) # ajuste dos dados no modelo\n",
    "\n",
    "y_pred = model.predict(x_test) # calculo da predicao\n",
    "print('Accuracy: ', model.score(x_test, y_test)) # mostrando a acur√°cia do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a vari√°vel original quality: A acur√°cia do modelo de naive bayes considerando os dados com uma distribui√ß√£o de Bernoulli, resultou numa acur√°cia de 0.5645833333333333, arredondando, temos uma acur√°cia de 0.6. Este resultado √© melhor comparado com o outro modelo de naive bayes usando distribui√ß√£o normal.\n",
    "\n",
    "Modelo considerando a vari√°vel criada qualidade: resultou numa acur√°cia igual a 0.7328431372549019 ou 0.7 (arredondando)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - SVM (encontre o melhor C usando valida√ß√£o cruzada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vk = [] # armazena os valores de k, cria√ß√£o de lista nula\n",
    "vscore = [] # armazena a m√©dia do test score, cria√ß√£o de lista nula\n",
    "for c in range(1, 20):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    model = SVC(C = c, gamma = 'auto')\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test) \n",
    "    score = accuracy_score(y_pred, y_test)\n",
    "    print('C:', c, 'accurace:', score) # mostra a c-√©sima acur√°cia do c-√©simo modelo\n",
    "    vscore.append(score) # armazena o resultado numa lista\n",
    "    vk.append(c) # armazenando o valor de k vizinhos na lista e populando a lista que antes era uma lista nula\n",
    "\n",
    "plt.plot(vk, vscore, '-bo') # fun√ß√£o de se construir um ambiente para plotar o gr√°fico\n",
    "plt.xlabel('c', fontsize = 15) # definindo o eixo x\n",
    "plt.ylabel('Accuracy', fontsize = 15) # definindo o eixo y\n",
    "plt.show(True) # plotando\n",
    "best_c = np.argmax(vscore)+1 # mostrando o melhor k com o argumento argmax dentro da lista criada\n",
    "print('Melhor c:', best_c) # mostrando o resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a vari√°vel original quality: O melhor C foi de 10, C: 10 accurace: 0.625, arredondando a acur√°cia, temos 0.6.\n",
    "\n",
    "Modelo considerando a vari√°vel criada qualidade: O melhor C foi C=1 com 0.7622549019607843 ou 0.8 de acur√°cia (arredondando)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 - Random Forest (encontre o melhor n√∫mero de estimadores usando valida√ß√£o cruzada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O m√©todo florestas aleat√≥rias considera amostragem de observa√ß√µes e atributos. Vamos realizar a classifica√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, bootstrap=True, criterion='gini',\n",
    "            max_features='auto', min_impurity_decrease=0.0, min_samples_leaf=1, \n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0, n_jobs=1,\n",
    "            oob_score=False, verbose=0, warm_start=False) # modelo de random forest\n",
    "\n",
    "model.fit(x_train,y_train) # ajuste do modelo com as vari√°veis utilizadas\n",
    "\n",
    "y_pred = model.predict(x_test) # Predict the response for test dataset\n",
    "score = accuracy_score(y_pred, y_test) # acur√°cia do modelo\n",
    "print('Accuracy:', score) # mostra a o resultado da acur√°cia do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a vari√°vel original quality: A acur√°cia para este modelo foi de 0.6729166666666667, arredondando temos a acur√°cia equivalente a 0.7. Um dos melhores resultados j√° vistos at√© ent√£o.\n",
    "\n",
    "Modelo considerando a vari√°vel criada qualidade: Resultou numa acur√°cia de 0.7647058823529411 ou 0.8 (arredondando)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos analisar como o n√∫mero de √°rvores influencia no resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vscore = []\n",
    "vn = []\n",
    "for n in range(1,100):\n",
    "    model = RandomForestClassifier(n_estimators=n)\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test) \n",
    "    score = accuracy_score(y_pred, y_test)\n",
    "    print('Number of Estimators:', n, 'Accuracy:', score)\n",
    "    vscore.append(score)\n",
    "    vn.append(n)\n",
    "best_n = vn[np.argmax(vscore)]\n",
    "print('Melhor n:', best_n, ' com acur√°cia:', vscore[np.argmax(vscore)] )\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(vn, vscore, '-bo')\n",
    "plt.xlabel('Number of Estimators', fontsize = 15)\n",
    "plt.ylabel('Accuracy', fontsize = 15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a vari√°vel original quality: O melhor n√∫mero de estimadores para o modelo de random forest foi de 56 estimadores com uma acur√°cia cravada em 0.7.\n",
    "\n",
    "Modelo considerando a vari√°vel criada qualidade: quantidade de 42 estimadores com 0.7818627450980392 ou 0.8 de acur√°cia (arredondando)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 - Para o algoritmo random forest, mostre a import√¢ncia de cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando o modelo considerado como o melhor, pela avalia√ß√£o anterior, temos\n",
    "model = RandomForestClassifier(n_estimators=42, bootstrap=True, criterion='gini',\n",
    "            max_features='auto', min_impurity_decrease=0.0, min_samples_leaf=1, \n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0, n_jobs=1,\n",
    "            oob_score=False, verbose=0, warm_start=False) # modelo de random forest\n",
    "\n",
    "model.fit(x_train,y_train) # ajuste do modelo com as vari√°veis utilizadas\n",
    "\n",
    "y_pred = model.predict(x_test) # Predict the response for test dataset\n",
    "score = accuracy_score(y_pred, y_test) # acur√°cia do modelo\n",
    "print('Accuracy:', score) # mostra a o resultado da acur√°cia do modelo\n",
    "\n",
    "importances = model.feature_importances_ # features mais importantes\n",
    "indices = np.argsort(importances) # os indices de onde estao \n",
    "lmeas_order = [] # ordenacao por relevancia das variaveis\n",
    "for i in indices: # plotagem\n",
    "    lmeas_order.append(features_names[i])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), lmeas_order, fontsize=15)\n",
    "plt.xlabel('Relative Importance',fontsize=15)\n",
    "plt.xticks(color='k', size=20)\n",
    "plt.yticks(color='k', size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vari√°vel que tem a maior import√¢ncia √© alcohol, seguido de sulphates e volatile acidity.\n",
    "\n",
    "Pesquisando sobre 'como avaliar se um vinho √© bom', h√° um artigo do clube do vinho falando de 3 fatores:√°lcool, acidez e taninos. (link: https://www.clubedosvinhos.com.br/qualidade-de-um-vinho/)\n",
    "\n",
    "A primeira vari√°vel que se mostrou importante foi realmente o teor alc√≥olico.\n",
    "A segunda √© o sulfato Os taninos est√£o ligados a adistringencia, quanto maior quantidade de taninos, os predadores tendem a nao comer a fruta, deixando a fruta intacta e proporcionando um melhor vinho.\n",
    "\n",
    "E a terceira o volatile acidity que tem a ver com a acidez do vinho.\n",
    "\n",
    "Nota: tem um tabu com rela√ß√£o aos taninos em rela√ß√£o ao gosto.Caso uma pessoa nao goste do gosto do vinho √© adicionado mais taninos artificiais, sem mudar a composi√ß√£o do vinho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 - Usando regress√£o linear, tente predizer a porcentagem de √°lcool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ajuste dos coeficientes da regress√£o linear √© feito usando apenas o conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42) # define a semente (importante para reproduzir os resultados)\n",
    "\n",
    "dir_file = '/home/andressa/Desktop/' # criando um objeto do meu diretorio do dataset\n",
    "\n",
    "os.chdir(dir_file) # setando aonde meu dataset est√°\n",
    "df = pd.read_csv('winequality-red.csv') # importando os dados\n",
    "\n",
    "print(\"N√∫mero de linhas e colunas no dataset:\", df.shape) # funcao de printar\n",
    "attributes = list(df.columns) # construindo um objeto tipo lista para armazenar os nomes das variaveis\n",
    "df.head(10) # funcao head para mostrar uma amostra do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcool = df.alcohol # separando a variavel alcohol do dataset e colocando no final\n",
    "df.drop(['alcohol'],axis = 1, inplace = True)\n",
    "df['alcohol'] = alcool\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertemos em formato numpy para facilitar a manipulacao dos dados\n",
    "df = df.to_numpy() # dataframe do pandas para array numpy\n",
    "nrow,ncol = df.shape # atribuindo aos objetos nrow e ncol o tamanho do conjunto de dados\n",
    "y = df[:,-1] # separando a variavel target\n",
    "X = df[:,0:ncol-1] # construindo o dataset de analise sem a variavel target\n",
    "\n",
    "print('Dados originais:') # mostrando a m√©dia e desvio padrao dos atributos do conjunto de dados X ja transformados\n",
    "print('Media: ', np.mean(X, axis = 0)) # m√©dia dos dados\n",
    "print('Desvio Padrao:', np.std(X, axis = 0)) # desvio padrao dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normaliza√ß√£o dos dados de forma a evitar problemas de escala nos atributos\n",
    "\n",
    "scaler = StandardScaler().fit(X) # normaliza√ß√£o dos dados\n",
    "X = scaler.transform(X) # tranforma√ß√£o dos dados\n",
    "\n",
    "print('Dados transformados:') # mostrando a m√©dia e desvio padrao dos atributos do conjunto de dados X ja transformados\n",
    "print('Media: ', np.mean(X, axis = 0)) # media dos dados padronizados\n",
    "print('Desvio Padrao:', np.std(X, axis = 0)) # desvio padrao dos dados padronizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "p = 0.3 # fracao de elementos no conjunto de teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = p, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression() # modelo de regress√£o linear m√∫ltipla\n",
    "lm.fit(x_train, y_train) # ajuste do modelo de regressao linear multipla\n",
    "\n",
    "y_pred = lm.predict(x_test) # valores preditos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notem que como temos v√°rias vari√°veis, n√£o √© poss√≠vel mostrar os resultados em mais de tr√™s dimens√µes. Nesse caso, uma maneira de visualizar a precis√£o na predi√ß√£o √© graficar os valores reais versus as predi√ß√µes, como mostramos abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() # plotagem\n",
    "l = plt.plot(y_pred, y_test, 'bo')\n",
    "plt.setp(l, markersize=10)\n",
    "plt.setp(l, markerfacecolor='C0')\n",
    "\n",
    "plt.ylabel(\"y\", fontsize=15) # ajustes dos eixos dos graficos\n",
    "plt.xlabel(\"Prediction\", fontsize=15)\n",
    "\n",
    "# mostra os valores preditos e originais\n",
    "xl = np.arange(min(y_test), 1.2*max(y_test),(max(y_test)-min(y_test))/10)\n",
    "yl = xl\n",
    "plt.plot(xl, yl, 'r--')\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quanto mais pr√≥ximo da reta em vermelho, melhor ser√° a predi√ß√£o, pois essa reta representa o caso em que  ùë¶ÃÇ =ùë¶ .\n",
    "\n",
    "Para quantificarmos o ajuste, calculamos o coeficiente R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print('R2:', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo de regress√£o linear apresentou um R2 de 0.706569863175307, arredondamos, temos 0.7 de R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentagem de alcool predita\n",
    "pd.DataFrame(y_pred).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A percentagem m√≠nima √© de 8 e a m√°xima de 13, atingindo parametros ideais de acordo com especialistas em vinho e indo de encontro com as an√°lises descritivas da base de teste.\n",
    "\n",
    "A mediana tamb√©m est√° similar a base original de teste e de treino. Assim como a m√©dia.O desvio padr√£o √© menor comparado com os dados de treino e de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 - Compare os m√©todos Lasso, Ridge Regression, calculando o erro quadr√°tico m√©dio em fun√ß√£o dos seus par√¢metros (alpha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vR2 = []\n",
    "valpha = []\n",
    "for alpha in np.arange(0.01,2,0.1):\n",
    "    lasso = Lasso(alpha = alpha, normalize = True)\n",
    "    lasso.fit(x_train, y_train)             # Fit a ridge regression on the training data\n",
    "    y_pred = lasso.predict(x_test)           # Use this model to predict the test data\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    vR2.append(r2)\n",
    "    valpha.append(alpha)\n",
    "plt.plot(valpha, vR2, '-ro')\n",
    "plt.xlabel(\"alpha\", fontsize=15)\n",
    "plt.ylabel(\"R2\", fontsize=15)\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vR2 = []\n",
    "valpha = []\n",
    "# variamos os valaores de alpha\n",
    "for alpha in np.arange(0,10,0.5):\n",
    "    ridge2 = Ridge(alpha = alpha, normalize = True)\n",
    "    ridge2.fit(x_train, y_train)             # Fit a ridge regression on the training data\n",
    "    y_pred = ridge2.predict(x_test)           # Use this model to predict the test data\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    vR2.append(r2)\n",
    "    valpha.append(alpha)\n",
    "plt.plot(valpha, vR2, '-ro')\n",
    "plt.xlabel(\"alpha\", fontsize=15)\n",
    "plt.ylabel(\"R2\", fontsize=15)\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que para o modelo de regressao linear multiplo, obtemos um R2 de 0.7 aproximadamente para para o lasso e ridge os maiores valores, quando alpha √© igual a 0, equiparam-se ao valor obtido no modelo de regressao linear multipla. Em termos computacionais mais se vale usar o modelo de regressao linear multipla do que se gastar processamento com otimizacoes que nao vao dar resultados melhores para a analise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 - Discuss√£o dos resultados obtidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifica√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo com vari√°vel original quality:\n",
    "    \n",
    "    KNN ============= k=1 ====== 0.6239480807086614 === 0.6\n",
    "    Arvore gini ================ 0.58125 ============== 0.6\n",
    "    Arvore entropia ============ 0.578125 ============= 0.6\n",
    "    Naive Bayes normal ========== 0.5375 ============== 0.5\n",
    "    Naive Bayes bernoulli ======= 0.5645833333333333 == 0.6\n",
    "    SVM ============= C=10 ====== 0.625 =============== 0.6\n",
    "    Random Forest === E=56 ====== 0.7 ================= 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo com vari√°vel criada qualidade (1 se maior ou igual a 6, 0 c.c.):\n",
    "    \n",
    "    KNN === k=8 ================ 0.7401973684210527 === 0.7\n",
    "    Arvore gini ================ 0.6642156862745098 === 0.7\n",
    "    Arvore entropia ============ 0.6421568627450981 === 0.6\n",
    "    Naive Bayes normal ========= 0.75 ================= 0.8\n",
    "    Naive Bayes bernoulli ====== 0.7328431372549019 === 0.7\n",
    "    SVM ============= C=1 ======= 0.7622549019607843 == 0.8\n",
    "    Random Forest === E=42 ====== 0.7818627450980392 == 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modelo de classifica√ß√£o\n",
    "\n",
    "Modelo considerando a vari√°vel original quality:\n",
    "    \n",
    "    Temos que o melhor modelo (com maior acur√°cia) foi o random forest, com 0.7.\n",
    "\n",
    "Modelo considerando a vari√°vel criada qualidade:\n",
    "    \n",
    "    Todos os modelos deram melhor resultados comparado com o uso da vari√°vel original. \n",
    "    Sendo o melhor deles o Random Forest seguido do SVM e Naive Bayes com crit√©rio da Normal.\n",
    "    \n",
    "* Modelo de Regress√£o para prever o teor alcoolico\n",
    "    \n",
    "    O melhor modelo foi o linear m√∫ltiplo, comparando com Lasso e Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em prol de todos estes resultadosvistos, podemos avaliar bem a classifica√ß√£o da qualidade de um vinho (bom ou ruim) considerando o modelo Random Forest, pois tem uma acur√°cia alta na hora de se prever uma nova nota ou novo vinho quanto a qualidade. E, para prever o teor de alc√≥ol dele, podemos usar o modelo de regress√£o linear m√∫ltipla que tem uma explica√ß√£o do modelo de 0.7 aproximadamente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
