{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Ciências de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Professor: Francisco Rodrigues\n",
    "##### Aluna: Andressa Contarato Rodrigues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O desenvolvimento desse projeto se dará através dos seguintes passos:\n",
    "    \n",
    "    * Pré-processamento\n",
    "    \n",
    "    1- Formulação do problema e preparo dos dados\n",
    "    2 - Limpeza e normalização dos dados\n",
    "    3- Transformação para valores numéricos (one-hot-encoding) se precisar.\n",
    "    \n",
    "    * Classificação (classificar de acordo com a qualidade)\n",
    "    \n",
    "    4 - kvizinhos (encontre o melhor k usando validação cruzada)\n",
    "    5 - Árvore de decisão\n",
    "    6 - Naive Bayes\n",
    "    7 - SVM (encontre o melhor C usando validação cruzada)\n",
    "    8 - Random Forest (encontre o melhor número de estimadores usando validação cruzada)\n",
    "    \n",
    "    * Ordenação dos atributos\n",
    "    \n",
    "    9 - Para o algoritmo random forest, mostre a importância de cada atributo.\n",
    "    \n",
    "    * Regressão\n",
    "    \n",
    "    10 - Usando regressão linear, tente predizer a porcentagem de álcool.\n",
    "    11 - Compare os métodos Lasso, Ridge Regression, calculando o erro quadrático médio em função dos seus parâmetros (alpha).\n",
    "    \n",
    "    * Conclusão\n",
    "    \n",
    "    12 - Discussão dos resultados obtidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow\"> Objetivo: Vamos considerar o problema de classificação dos de vinhos disponível no portal Kaggle (link: https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009).\n",
    "Ou seja, objetivamos construir um projeto para classificar os dados, de modo a verificar o quão preciso são nossos resultados comparados com soluções de outros usuários. \n",
    "Vamos mostrar todas as fases do projeto e os resultados, mas lembramos que essa é uma possível solução. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso objetivo é classificar o vinho de acordo com a qualidade dele e predizer o teor alcóolico deste vinho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulação do problema e leitura dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos considerar a base de dados de vinhos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos contidos nos dados\n",
    "\n",
    "1 - fixed acidity: a maioria dos ácidos envolvidos no vinho ou fixa ou não volátil (não evapore rapidamente) \n",
    "\n",
    "2 - volatile acidity: a quantidade de ácido acético no vinho, que em níveis muito altos pode levar a um sabor desagradável ao vinagre \n",
    "\n",
    "3 - citric acid: encontrado em pequenas quantidades, o ácido cítrico pode adicionar 'frescura' e sabor aos vinhos\n",
    "\n",
    "4 - residual sugar: a quantidade de açúcar restante após o término da fermentação, é raro encontrar vinhos com menos de 1 grama / litro e vinhos com mais de 45 gramas / litro são considerados doces \n",
    "\n",
    "5 - chlorides: a quantidade de sal no vinho \n",
    "\n",
    "6 - free sulfur dioxide: a forma livre de SO2 existe em equilíbrio entre o SO2 molecular (como um gás dissolvido) e o íon bissulfito; impede o crescimento microbiano e a oxidação do vinho \n",
    "\n",
    "7 - total sulfur dioxide: formas livres e ligadas de S02; em baixas concentrações, o SO2 é principalmente indetectável no vinho, mas em concentrações livres de SO2 acima de 50 ppm, o SO2 se torna evidente no nariz e no sabor do vinho \n",
    "\n",
    "8 - density: a densidade da água no vinho é próxima à da água, dependendo da porcentagem de teor de álcool e açúcar \n",
    "\n",
    "9 - pH: descreve como um vinho é ácido ou básico em uma escala de 0 (muito ácido) a 14 (muito básico); a maioria dos vinhos tem entre 3-4 na escala de pH \n",
    "\n",
    "10 - sulphates: um aditivo de vinho que pode contribuir para os níveis de gás dióxido de enxofre (S02), que atua como antimicrobiano e antioxidante \n",
    "\n",
    "11 - alcohol: a percentagem de álcool do vinho \n",
    "\n",
    "12 - quality: variável de saída de qualidade (com base em dados sensoriais, pontuação entre 0 e 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando os pacotes necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dentro da linguagem pandas ha vários métodos e funções pré-definidas, porém muitas das quais vamos utilizar aqui, \n",
    "# temos que 'chamar' através de uma estrutura import ou se for um módulo \n",
    "# de uma biblioteca, através do from.\n",
    "\n",
    "import matplotlib.pyplot as plt # módulo matplotlib para construcao de graficos\n",
    "import numpy as np # biblioteca pandas usada para manipulação de dados, tb da forma big data e construção de métricas\n",
    "import os # biblioteca python para setar egerenciar arquivos localmente\n",
    "import pandas as pd # biblioteca Pandas é usada para manipulação de dados\n",
    "import random # módulo do Numpy de geração de números randomicos\n",
    "from sklearn.preprocessing import StandardScaler # módulo do sklearn para padronização dos dados do sklearn para padronizacao e normalizacao dos dados\n",
    "from sklearn.model_selection import train_test_split # módulo do sklearn para separar dados de teste e de treino\n",
    "from sklearn.model_selection import cross_validate # módulo sklearn para validação cruzada\n",
    "from sklearn.neighbors import KNeighborsClassifier # módulo sklearn para calcular o modelo de machine learning knn\n",
    "from sklearn import tree # importando o módulo do sklearn do modelo de árvore de decisão\n",
    "from sklearn.metrics import accuracy_score # para calculo da acurácia em módulos que nao se tem implementados\n",
    "from sklearn import tree # importando módulo de visualização da árvore\n",
    "from sklearn.naive_bayes import GaussianNB # módulo do sklearn para implementação do modelo de Naive Bayes com distribuição normal\n",
    "from sklearn import metrics # módulo do sklearn para computação de métricas dentro do modelo de naive bayes\n",
    "from sklearn.naive_bayes import BernoulliNB # módulo do sklearn para implementação do modelo de Naive Bayes com distribuição bernoulli\n",
    "from sklearn.ensemble import RandomForestClassifier # módulo do sklearn para construção do modelo de Random Forest\n",
    "from sklearn.linear_model import LinearRegression # módulo sklearn para regressao linear\n",
    "from sklearn.decomposition import PCA # módulo sklearn para construção da pca\n",
    "from sklearn.model_selection import train_test_split # módulo sklearn para construcao do split para dataset de teste e de treino num modelo de regressao linear\n",
    "from sklearn.linear_model import Lasso # módulo sklearn para importacao da métrica de lasso\n",
    "from sklearn.metrics import mean_squared_error # módulo sklear para importacao da estatistica de teste erro quadrático médio\n",
    "from sklearn.metrics import r2_score # módulo sklear para importacao da estatistica de teste R2\n",
    "from sklearn.linear_model import Ridge, RidgeCV # módulo sklearn para importacao da métrica de ridge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Formulação do problema e preparo dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42) # define a semente (importante para reproduzir os resultados)\n",
    "\n",
    "dir_file = '' # insira o diretório onde se encontra o dataset\n",
    "# ex.: /home/andressa/Desktop/\n",
    "# criando um objeto do meu diretorio do dataset\n",
    "os.chdir(dir_file) # setando aonde meu dataset está\n",
    "df = pd.read_csv('winequality-red.csv') # importando os dados\n",
    "\n",
    "print(\"Número de linhas e colunas no dataset:\", df.shape) # funcao de printar\n",
    "attributes = list(df.columns) # construindo um objeto tipo lista para armazenar os nomes das variaveis\n",
    "features_names = df.columns\n",
    "df.head(10) # funcao head para mostrar uma amostra do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a classificação há resultados melhores, quanto a acurácia dos modelos, o que será apresentado são os resultados do modelo com uma construção de uma nova target que seja categórica e dicotômica. \n",
    "\n",
    "Todavia, há também escrito a comparação entre modelos usando a variável original quality como target e a variável qualidade criada. \n",
    "\n",
    "A variável qualidade receberá 1 se o vinho for classificado com uma nota maior ou igual a 6 e 0 caso contrário, considerando a média da qualidade dos vinhos descrito na análise descritiva acima e arredondando uma casa decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando uma variavel categorica\n",
    "\n",
    "qualidade = []\n",
    "for i in range(0,df.shape[0]):\n",
    "    if df.iloc[i,11] < 6:\n",
    "        qualidade.append(0)\n",
    "    else:\n",
    "        qualidade.append(1)\n",
    "df['qualidade'] = qualidade\n",
    "df.head()\n",
    "\n",
    "df = df.drop(['quality'], axis=1) # removendo a coluna quality\n",
    "\n",
    "# Obs: se for analisar a quality, nao rodar esta célula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Limpeza e normalização dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados pode apresentar valores nulos (not a number: nan). A sua identificação pode ser feita usando métodos da biblioteca Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False).head(10)# verificação se há valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado mostrou que não há valores faltantes na base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() # reomoção de valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não apresenta nenhum valor faltante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna True na posição em que há uma linha duplicada\n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apresenta valor duplicado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove as linhas duplicadas\n",
    "df = df.drop_duplicates()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso o tamanho da base de dados também se altera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar se as classes estão balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df[df.columns[-1]] # considerando quality original do dataset\n",
    "# classes = df[df.columns[-2]]\n",
    "cl = np.unique(classes)\n",
    "ncl = np.zeros(len(cl))\n",
    "for i in np.arange(0, len(cl)):\n",
    "    a = classes == cl[i]\n",
    "    ncl[i] = len(classes[a])\n",
    "    \n",
    "numbers = np.arange(0, len(cl))\n",
    "plt.bar(numbers, ncl,  alpha=.75)\n",
    "plt.xticks(numbers, cl)\n",
    "plt.title('Número de elementos em cada classe')\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a variável quality original: Há mais vinhos classificados como 5 e 6, tendo um desbalanceamento dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a variável qualidade criada: há um melhor balanceamento considerando vinhos classificados maior ou igual a 6 como bons (atributo 1) e 0 caso contrário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise Descritiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos valores muito discrepantes entre as variaveis, vide o maximo da total sulfur dioxide com a density. E, na variável também, vide a total sulfur dioxide novamente. Necessitando de uma normalização dos dados.\n",
    "Em média, a pontuação do vinho é de boa qualidade (considerando acima de 4 bom).\n",
    "A variação da quality é muito pequena e a variação do total sulfur dioxide é uma das maiores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertemos em formato numpy para facilitar a manipulacao dos dados\n",
    "data = df.to_numpy() # dataframe do pandas para array numpy\n",
    "nrow,ncol = data.shape # atribuindo aos objetos nrow e ncol o tamanho do conjunto de dados\n",
    "\n",
    "y = data[:,-1] # considerando quality\n",
    "# X = data[:,0:ncol-2] # construindo o dataset de analise sem a variavel target\n",
    "# retirando a quality para analisar a qualidade como y, variavel target\n",
    "\n",
    "X = data[:,0:ncol-1]\n",
    "\n",
    "print('Dados originais:') # mostrando a média e desvio padrao dos atributos do conjunto de dados X ja transformados\n",
    "print('Media: ', np.mean(X, axis = 0))\n",
    "print('Desvio Padrao:', np.std(X, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalização dos dados de forma a evitar problemas de escala nos atributos\n",
    "scaler = StandardScaler().fit(X) # normalização dos dados\n",
    "X = scaler.transform(X) # tranformação dos dados\n",
    "\n",
    "print('Dados transformados:') # mostrando a média e desvio padrao dos atributos do conjunto de dados X ja transformados\n",
    "print('Media: ', np.mean(X, axis = 0))\n",
    "print('Desvio Padrao:', np.std(X, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados aqui ficaram numa escala variando de -8 até 4 aproximadamente (arredondando). Mas a distancia entre eles ficou menor comparado com o dataset original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ter uma ideia da separação entre as classes realizando a projeção dos atributos em duas dimensões usando PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(X)\n",
    "\n",
    "classes = np.unique(y)\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "aux = 0\n",
    "plt.figure(figsize=(8,5))\n",
    "for c in classes:\n",
    "    if c == 1:\n",
    "        lb = 'Bom'\n",
    "    else:\n",
    "        lb = 'Ruim'\n",
    "    nodes = np.where(y == c)\n",
    "    plt.scatter(pca_result[nodes,0], pca_result[nodes,1], s=50, color = colors[aux], label = lb)\n",
    "    aux = aux + 1\n",
    "plt.legend()\n",
    "plt.xlabel(\"First component\", fontsize=20)\n",
    "plt.ylabel(\"Second component\", fontsize=20)\n",
    "plt.xticks(color='k', size=20)\n",
    "plt.yticks(color='k', size=20)\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando a variável original quality: temos que o gráfico apresentou uma não separação dos dados e 7 classificações diferentes. \n",
    "\n",
    "Considerando a variável criada qualidade: temos que em duas dimensões, a separação não é clara, porém uma hipóteses é que seja mais fácil de se determinar a saída com um menor número de classes e distanciando mais as características.\n",
    "\n",
    "Além disso, podemos identificar os atributos que mais explicam a variância nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(X)\n",
    "var_exp = pca.explained_variance_ratio_\n",
    "\n",
    "importances = var_exp\n",
    "attributes = df.columns[1:len(df.iloc[:,0:df.shape[0]-1].columns)] # considerando quality\n",
    "indices = np.argsort(importances)\n",
    "attributes_rank = []\n",
    "for i in indices:\n",
    "    attributes_rank.append(attributes[i])\n",
    "plt.title('Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), attributes_rank, fontsize=25)\n",
    "plt.xlabel('Relative Importance',fontsize=25)\n",
    "plt.xticks(color='k', size=20)\n",
    "plt.yticks(color='k', size=20)\n",
    "plt.xlim([0.0, 0.25])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando a variável quality original: tem-se a seguinte análise: as classes maiores (classificando o vinho como bom) estão mais relacionadas as variáveis: volatile acidity, citric acid e residual sugar.\n",
    "\n",
    "\n",
    "Considerando a variável criada, qualidade: a classe cujo o vinho é classificado como bom (maior ou igual a 6), está intimamente relacionado mais com os atributos volatile acidity, citric acid e residual sugar. Logo, podemos considerar apenas os atributos mais importantes na classificação. No entanto, vamos inicialmente manter esses atributos em nossos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos verificar como a variância muda de acordo com o número de componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X)\n",
    "plt.figure(figsize=(8,5))\n",
    "ncomp = np.arange(1, np.shape(X)[1]+1)\n",
    "plt.plot(ncomp, np.cumsum(pca.explained_variance_ratio_), 'ro-')\n",
    "plt.xlabel('number of components', fontsize=20)\n",
    "plt.ylabel('cumulative explained variance', fontsize=20);\n",
    "plt.xticks(color='k', size=20)\n",
    "plt.yticks(color='k', size=20)\n",
    "plt.grid(True)\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que com 7 componentes explicamos cerca de 90% dos dados. No entanto, como o número de atributos não é elevado, vamos considerar os dados sem seleção dos atributos principais, ou seja, os dados sem usar a projeção. (Mesma análise considerando a variável quality original e a variável qualidade criada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também analisar o nível de correlação nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "#Plot Correlation Matrix using Matplotlib\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(corr, cmap='Blues', interpolation='none', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr)), corr.columns, rotation='vertical')\n",
    "plt.yticks(range(len(corr)), corr.columns);\n",
    "plt.suptitle('Correlation between variables', fontsize=15, fontweight='bold')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que as variáveis mais correlacionadas são:\n",
    "\n",
    "volatile acidity x citric acid\n",
    "\n",
    "density x fixed acidity\n",
    "\n",
    "(Mesma análise considerando a variável quality original e a variável qualidade criada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Transformação para valores numéricos (one-hot-encoding) se precisar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados aqui são todos numéricos, não fazendo necessária esta etapa de one-hot-enconding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para treinar o classificador, precisamos dividir o dataset em conjunto de teste e de treino\n",
    "\n",
    "p = 0.3 # fracao de elementos no conjunto de teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = p, random_state = 42) # dividindo o dataset em teste e treino, de acordo com p que é a porcentagem de dados que quero ter em cada dataset\n",
    "# no caso, definimos 0.3 para teste o 0.7 para treino\n",
    "# A partir desse conjunto de dados, podemos realizar a classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi separado 30% para dados de teste e 70% para dados de treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - kvizinhos (encontre o melhor k usando validação cruzada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro método usado aqui para classificação será o método dos vizinhos mais póximos, ou knn. O knn é baseado no conceito de distância entre atributos. Para realizar a classificação, vamos usar a biblioteca scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nkf = 10 # número de folds\n",
    "vk = [] # armazena os valores de k, criação de lista nula\n",
    "vscore = [] # armazena a média do test score, criação de lista nula\n",
    "for k in range(1, 20):\n",
    "    model = KNeighborsClassifier(n_neighbors=k, metric = 'euclidean') # modelo knn considerando a distancia euclidiana com o argumento metric = 'euclidian'\n",
    "    cv = cross_validate(model, x_train, y_train, cv=nkf) # realiza a validação cruzada\n",
    "    print('k:', k, 'accurace:', cv['test_score'].mean()) # mostra a k-ésima acurácia do k-ésimo modelo\n",
    "    vscore.append(cv['test_score'].mean()) # armazena o resultado numa lista\n",
    "    vk.append(k) # armazenando o valor de k vizinhos na lista e populando a lista que antes era uma lista nula\n",
    "\n",
    "plt.plot(vk, vscore, '-bo') # função de se construir um ambiente para plotar o gráfico\n",
    "plt.xlabel('k', fontsize = 15) # definindo o eixo x\n",
    "plt.ylabel('Accuracy', fontsize = 15) # definindo o eixo y\n",
    "plt.show(True) # plotando\n",
    "best_k = np.argmax(vscore)+1 # mostrando o melhor k com o argumento argmax dentro da lista criada\n",
    "print('Melhor k:', best_k) # mostrando o resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a variável original quality: O melhor k foi k=1 com uma acurácia de 0.6239480807086614, arrendondando para uma casa decimal, temos acurácia igual a 0.6 \n",
    "\n",
    "Modelo considerando a variável criada qualidade: o melhor k foi 8 com uma acurácia de 0.7401973684210527 ou 0.7 (arredondando)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterio de gini\n",
    "model = tree.DecisionTreeClassifier(criterion = 'gini', random_state = 101) # Cria o modelo usando o criterio Gini\n",
    "model.fit(x_train,y_train) # Ajusta o modelo usando os dados de treinamento\n",
    "y_pred = model.predict(x_test) # realizar a predição\n",
    "score = accuracy_score(y_pred, y_test) # calcula a acuracia\n",
    "print('Accuracy:', score) # mostrando a acurácia do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a variável quality: A acurácia do modelo de árvore de decisão considerando o criterio de gini, resultou numa acurácia de 0.58125, arredondando, temos uma acurácia de 0.6 (arredondando). Ainda, neste modelo, houve uma arvore muito grande e confusa por haver mais possibilidades de classificação, tendo uma análise gráfica mais complexa.\n",
    "\n",
    "Modelo considerando a variável qualidade: usando o critério de gini temos a acurácia de 0.6642156862745098 ou 0.7 (arredondando). A árvore ficou mais simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(x_train,y_train) # modelo de arvore de decisao\n",
    "plt.figure(figsize=(15,10)) # plotando a figura\n",
    "tree.plot_tree(model, filled = True) # estrutura da figura\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando a medida de entropia\n",
    "model = tree.DecisionTreeClassifier(criterion = 'entropy',random_state = 101)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test) \n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a variável quality: a acurácia do modelo de árvore de decisão considerando o criterio de entropia, resultou numa acurácia de 0.578125, arredondando, temos uma acurácia de 0.6 (arredondando). Ainda, neste modelo, houve uma arvore muito grande e confusa por haver mais possibilidades de classificação, tendo uma análise gráfica mais complexa.\n",
    "\n",
    "Modelo considerando a variável qualidade: usando o critério de entropia temos a acurácia de 0.6421568627450981 ou 0.6 (arredondando). Aqui se obteve uma árvore mais simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(x_train,y_train) # modelo de arvore de decisao\n",
    "plt.figure(figsize=(15,10)) # plotando a figura\n",
    "tree.plot_tree(model, filled = True) # estrutura da figura\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limitando o tamanho da arvore\n",
    "model = tree.DecisionTreeClassifier(criterion = 'gini', max_depth = 2, random_state = 101) # cria o modelo com número máximo de níveis max_depth\n",
    "model.fit(x_train,y_train) # ajusta aos dados de treinamento\n",
    "y_pred = model.predict(x_test) # faz a predição usando os dados de teste\n",
    "score = accuracy_score(y_pred, y_test) # calcula a acurácia\n",
    "print('Accuracy:', score) # mostra o resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limitando o tamanho da arvore\n",
    "model = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 2, random_state = 101) # cria o modelo com número máximo de níveis max_depth\n",
    "model.fit(x_train,y_train) # ajusta aos dados de treinamento\n",
    "y_pred = model.predict(x_test) # faz a predição usando os dados de teste\n",
    "score = accuracy_score(y_pred, y_test) # calcula a acurácia\n",
    "print('Accuracy:', score) # mostra o resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerndo a variável original quality: O melhor modelo é da árvore de decisão usando o critério de gini, se considerarmos todas as casas decimais, caso contrário os dois modelos são bons. Limitando os dados, temos um decréscimo na acurácia considerando tanto o modelo de gini quanto de entropia, ambos cairam para uma acurácia de 0.53125, ou 0.5. Utilizando a árvore de decisão completa, temos que a árvore com o critério de entropia apresenta um distribuição maior num ramo só da árvore, enquanto considerando o criterio de gini, a distribuição dos ramos são praticamente homogeneas. \n",
    "\n",
    "Modelo considerando a variável criada qualidade: considerando o critério de gini temos 0.678921568627451 ou 0.7 (arredondando) e considerando a entropia temos 0.6715686274509803 ou 0.7 (arredondando)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No classificador Naive Bayes, podemos assumir que os atributos são normalmente distribuídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print('Accuracy: ', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a variável original quality: A acurácia do modelo de naive bayes considerando os dados com uma distribuição de Normal, resultou numa acurácia de 0.5375, arredondando, temos uma acurácia de 0.5.\n",
    "\n",
    "Modelo considerando a variável criada qualidade: a acurácia foi de 0.75 ou 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra maneira de efetuarmos a classificação é assumirmos que os atributos possuem distribuição diferente da normal. Uma possibilidade é assumirmos que os dados possuem distribuição de Bernoulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos a função BernoulliNB para realizar a classificação usando a distribuição de Bernoulli\n",
    "model = BernoulliNB() # modelo considerando os dados com distribuição de bernoulli\n",
    "model.fit(x_train, y_train) # ajuste dos dados no modelo\n",
    "\n",
    "y_pred = model.predict(x_test) # calculo da predicao\n",
    "print('Accuracy: ', model.score(x_test, y_test)) # mostrando a acurácia do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a variável original quality: A acurácia do modelo de naive bayes considerando os dados com uma distribuição de Bernoulli, resultou numa acurácia de 0.5645833333333333, arredondando, temos uma acurácia de 0.6. Este resultado é melhor comparado com o outro modelo de naive bayes usando distribuição normal.\n",
    "\n",
    "Modelo considerando a variável criada qualidade: resultou numa acurácia igual a 0.7328431372549019 ou 0.7 (arredondando)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 - SVM (encontre o melhor C usando validação cruzada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vk = [] # armazena os valores de k, criação de lista nula\n",
    "vscore = [] # armazena a média do test score, criação de lista nula\n",
    "for c in range(1, 20):\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    model = SVC(C = c, gamma = 'auto')\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test) \n",
    "    score = accuracy_score(y_pred, y_test)\n",
    "    print('C:', c, 'accurace:', score) # mostra a c-ésima acurácia do c-ésimo modelo\n",
    "    vscore.append(score) # armazena o resultado numa lista\n",
    "    vk.append(c) # armazenando o valor de k vizinhos na lista e populando a lista que antes era uma lista nula\n",
    "\n",
    "plt.plot(vk, vscore, '-bo') # função de se construir um ambiente para plotar o gráfico\n",
    "plt.xlabel('c', fontsize = 15) # definindo o eixo x\n",
    "plt.ylabel('Accuracy', fontsize = 15) # definindo o eixo y\n",
    "plt.show(True) # plotando\n",
    "best_c = np.argmax(vscore)+1 # mostrando o melhor k com o argumento argmax dentro da lista criada\n",
    "print('Melhor c:', best_c) # mostrando o resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a variável original quality: O melhor C foi de 10, C: 10 accurace: 0.625, arredondando a acurácia, temos 0.6.\n",
    "\n",
    "Modelo considerando a variável criada qualidade: O melhor C foi C=1 com 0.7622549019607843 ou 0.8 de acurácia (arredondando)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 - Random Forest (encontre o melhor número de estimadores usando validação cruzada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método florestas aleatórias considera amostragem de observações e atributos. Vamos realizar a classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, bootstrap=True, criterion='gini',\n",
    "            max_features='auto', min_impurity_decrease=0.0, min_samples_leaf=1, \n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0, n_jobs=1,\n",
    "            oob_score=False, verbose=0, warm_start=False) # modelo de random forest\n",
    "\n",
    "model.fit(x_train,y_train) # ajuste do modelo com as variáveis utilizadas\n",
    "\n",
    "y_pred = model.predict(x_test) # Predict the response for test dataset\n",
    "score = accuracy_score(y_pred, y_test) # acurácia do modelo\n",
    "print('Accuracy:', score) # mostra a o resultado da acurácia do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a variável original quality: A acurácia para este modelo foi de 0.6729166666666667, arredondando temos a acurácia equivalente a 0.7. Um dos melhores resultados já vistos até então.\n",
    "\n",
    "Modelo considerando a variável criada qualidade: Resultou numa acurácia de 0.7647058823529411 ou 0.8 (arredondando)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos analisar como o número de árvores influencia no resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vscore = []\n",
    "vn = []\n",
    "for n in range(1,100):\n",
    "    model = RandomForestClassifier(n_estimators=n)\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test) \n",
    "    score = accuracy_score(y_pred, y_test)\n",
    "    print('Number of Estimators:', n, 'Accuracy:', score)\n",
    "    vscore.append(score)\n",
    "    vn.append(n)\n",
    "best_n = vn[np.argmax(vscore)]\n",
    "print('Melhor n:', best_n, ' com acurácia:', vscore[np.argmax(vscore)] )\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(vn, vscore, '-bo')\n",
    "plt.xlabel('Number of Estimators', fontsize = 15)\n",
    "plt.ylabel('Accuracy', fontsize = 15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerando a variável original quality: O melhor número de estimadores para o modelo de random forest foi de 56 estimadores com uma acurácia cravada em 0.7.\n",
    "\n",
    "Modelo considerando a variável criada qualidade: quantidade de 42 estimadores com 0.7818627450980392 ou 0.8 de acurácia (arredondando)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 - Para o algoritmo random forest, mostre a importância de cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando o modelo considerado como o melhor, pela avaliação anterior, temos\n",
    "model = RandomForestClassifier(n_estimators=42, bootstrap=True, criterion='gini',\n",
    "            max_features='auto', min_impurity_decrease=0.0, min_samples_leaf=1, \n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0, n_jobs=1,\n",
    "            oob_score=False, verbose=0, warm_start=False) # modelo de random forest\n",
    "\n",
    "model.fit(x_train,y_train) # ajuste do modelo com as variáveis utilizadas\n",
    "\n",
    "y_pred = model.predict(x_test) # Predict the response for test dataset\n",
    "score = accuracy_score(y_pred, y_test) # acurácia do modelo\n",
    "print('Accuracy:', score) # mostra a o resultado da acurácia do modelo\n",
    "\n",
    "importances = model.feature_importances_ # features mais importantes\n",
    "indices = np.argsort(importances) # os indices de onde estao \n",
    "lmeas_order = [] # ordenacao por relevancia das variaveis\n",
    "for i in indices: # plotagem\n",
    "    lmeas_order.append(features_names[i])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), lmeas_order, fontsize=15)\n",
    "plt.xlabel('Relative Importance',fontsize=15)\n",
    "plt.xticks(color='k', size=20)\n",
    "plt.yticks(color='k', size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável que tem a maior importância é alcohol, seguido de sulphates e volatile acidity.\n",
    "\n",
    "Pesquisando sobre 'como avaliar se um vinho é bom', há um artigo do clube do vinho falando de 3 fatores:álcool, acidez e taninos. (link: https://www.clubedosvinhos.com.br/qualidade-de-um-vinho/)\n",
    "\n",
    "A primeira variável que se mostrou importante foi realmente o teor alcóolico.\n",
    "A segunda é o sulfato Os taninos estão ligados a adistringencia, quanto maior quantidade de taninos, os predadores tendem a nao comer a fruta, deixando a fruta intacta e proporcionando um melhor vinho.\n",
    "\n",
    "E a terceira o volatile acidity que tem a ver com a acidez do vinho.\n",
    "\n",
    "Nota: tem um tabu com relação aos taninos em relação ao gosto.Caso uma pessoa nao goste do gosto do vinho é adicionado mais taninos artificiais, sem mudar a composição do vinho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 - Usando regressão linear, tente predizer a porcentagem de álcool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ajuste dos coeficientes da regressão linear é feito usando apenas o conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42) # define a semente (importante para reproduzir os resultados)\n",
    "\n",
    "dir_file = '/home/andressa/Desktop/' # criando um objeto do meu diretorio do dataset\n",
    "\n",
    "os.chdir(dir_file) # setando aonde meu dataset está\n",
    "df = pd.read_csv('winequality-red.csv') # importando os dados\n",
    "\n",
    "print(\"Número de linhas e colunas no dataset:\", df.shape) # funcao de printar\n",
    "attributes = list(df.columns) # construindo um objeto tipo lista para armazenar os nomes das variaveis\n",
    "df.head(10) # funcao head para mostrar uma amostra do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcool = df.alcohol # separando a variavel alcohol do dataset e colocando no final\n",
    "df.drop(['alcohol'],axis = 1, inplace = True)\n",
    "df['alcohol'] = alcool\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertemos em formato numpy para facilitar a manipulacao dos dados\n",
    "df = df.to_numpy() # dataframe do pandas para array numpy\n",
    "nrow,ncol = df.shape # atribuindo aos objetos nrow e ncol o tamanho do conjunto de dados\n",
    "y = df[:,-1] # separando a variavel target\n",
    "X = df[:,0:ncol-1] # construindo o dataset de analise sem a variavel target\n",
    "\n",
    "print('Dados originais:') # mostrando a média e desvio padrao dos atributos do conjunto de dados X ja transformados\n",
    "print('Media: ', np.mean(X, axis = 0)) # média dos dados\n",
    "print('Desvio Padrao:', np.std(X, axis = 0)) # desvio padrao dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalização dos dados de forma a evitar problemas de escala nos atributos\n",
    "\n",
    "scaler = StandardScaler().fit(X) # normalização dos dados\n",
    "X = scaler.transform(X) # tranformação dos dados\n",
    "\n",
    "print('Dados transformados:') # mostrando a média e desvio padrao dos atributos do conjunto de dados X ja transformados\n",
    "print('Media: ', np.mean(X, axis = 0)) # media dos dados padronizados\n",
    "print('Desvio Padrao:', np.std(X, axis = 0)) # desvio padrao dos dados padronizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "p = 0.3 # fracao de elementos no conjunto de teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = p, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression() # modelo de regressão linear múltipla\n",
    "lm.fit(x_train, y_train) # ajuste do modelo de regressao linear multipla\n",
    "\n",
    "y_pred = lm.predict(x_test) # valores preditos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notem que como temos várias variáveis, não é possível mostrar os resultados em mais de três dimensões. Nesse caso, uma maneira de visualizar a precisão na predição é graficar os valores reais versus as predições, como mostramos abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() # plotagem\n",
    "l = plt.plot(y_pred, y_test, 'bo')\n",
    "plt.setp(l, markersize=10)\n",
    "plt.setp(l, markerfacecolor='C0')\n",
    "\n",
    "plt.ylabel(\"y\", fontsize=15) # ajustes dos eixos dos graficos\n",
    "plt.xlabel(\"Prediction\", fontsize=15)\n",
    "\n",
    "# mostra os valores preditos e originais\n",
    "xl = np.arange(min(y_test), 1.2*max(y_test),(max(y_test)-min(y_test))/10)\n",
    "yl = xl\n",
    "plt.plot(xl, yl, 'r--')\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quanto mais próximo da reta em vermelho, melhor será a predição, pois essa reta representa o caso em que  𝑦̂ =𝑦 .\n",
    "\n",
    "Para quantificarmos o ajuste, calculamos o coeficiente R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print('R2:', R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo de regressão linear apresentou um R2 de 0.706569863175307, arredondamos, temos 0.7 de R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentagem de alcool predita\n",
    "pd.DataFrame(y_pred).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A percentagem mínima é de 8 e a máxima de 13, atingindo parametros ideais de acordo com especialistas em vinho e indo de encontro com as análises descritivas da base de teste.\n",
    "\n",
    "A mediana também está similar a base original de teste e de treino. Assim como a média.O desvio padrão é menor comparado com os dados de treino e de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 - Compare os métodos Lasso, Ridge Regression, calculando o erro quadrático médio em função dos seus parâmetros (alpha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vR2 = []\n",
    "valpha = []\n",
    "for alpha in np.arange(0.01,2,0.1):\n",
    "    lasso = Lasso(alpha = alpha, normalize = True)\n",
    "    lasso.fit(x_train, y_train)             # Fit a ridge regression on the training data\n",
    "    y_pred = lasso.predict(x_test)           # Use this model to predict the test data\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    vR2.append(r2)\n",
    "    valpha.append(alpha)\n",
    "plt.plot(valpha, vR2, '-ro')\n",
    "plt.xlabel(\"alpha\", fontsize=15)\n",
    "plt.ylabel(\"R2\", fontsize=15)\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vR2 = []\n",
    "valpha = []\n",
    "# variamos os valaores de alpha\n",
    "for alpha in np.arange(0,10,0.5):\n",
    "    ridge2 = Ridge(alpha = alpha, normalize = True)\n",
    "    ridge2.fit(x_train, y_train)             # Fit a ridge regression on the training data\n",
    "    y_pred = ridge2.predict(x_test)           # Use this model to predict the test data\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    vR2.append(r2)\n",
    "    valpha.append(alpha)\n",
    "plt.plot(valpha, vR2, '-ro')\n",
    "plt.xlabel(\"alpha\", fontsize=15)\n",
    "plt.ylabel(\"R2\", fontsize=15)\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que para o modelo de regressao linear multiplo, obtemos um R2 de 0.7 aproximadamente para para o lasso e ridge os maiores valores, quando alpha é igual a 0, equiparam-se ao valor obtido no modelo de regressao linear multipla. Em termos computacionais mais se vale usar o modelo de regressao linear multipla do que se gastar processamento com otimizacoes que nao vao dar resultados melhores para a analise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 - Discussão dos resultados obtidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo com variável original quality:\n",
    "    \n",
    "    KNN ============= k=1 ====== 0.6239480807086614 === 0.6\n",
    "    Arvore gini ================ 0.58125 ============== 0.6\n",
    "    Arvore entropia ============ 0.578125 ============= 0.6\n",
    "    Naive Bayes normal ========== 0.5375 ============== 0.5\n",
    "    Naive Bayes bernoulli ======= 0.5645833333333333 == 0.6\n",
    "    SVM ============= C=10 ====== 0.625 =============== 0.6\n",
    "    Random Forest === E=56 ====== 0.7 ================= 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo com variável criada qualidade (1 se maior ou igual a 6, 0 c.c.):\n",
    "    \n",
    "    KNN === k=8 ================ 0.7401973684210527 === 0.7\n",
    "    Arvore gini ================ 0.6642156862745098 === 0.7\n",
    "    Arvore entropia ============ 0.6421568627450981 === 0.6\n",
    "    Naive Bayes normal ========= 0.75 ================= 0.8\n",
    "    Naive Bayes bernoulli ====== 0.7328431372549019 === 0.7\n",
    "    SVM ============= C=1 ======= 0.7622549019607843 == 0.8\n",
    "    Random Forest === E=42 ====== 0.7818627450980392 == 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modelo de classificação\n",
    "\n",
    "Modelo considerando a variável original quality:\n",
    "    \n",
    "    Temos que o melhor modelo (com maior acurácia) foi o random forest, com 0.7.\n",
    "\n",
    "Modelo considerando a variável criada qualidade:\n",
    "    \n",
    "    Todos os modelos deram melhor resultados comparado com o uso da variável original. \n",
    "    Sendo o melhor deles o Random Forest seguido do SVM e Naive Bayes com critério da Normal.\n",
    "    \n",
    "* Modelo de Regressão para prever o teor alcoolico\n",
    "    \n",
    "    O melhor modelo foi o linear múltiplo, comparando com Lasso e Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em prol de todos estes resultadosvistos, podemos avaliar bem a classificação da qualidade de um vinho (bom ou ruim) considerando o modelo Random Forest, pois tem uma acurácia alta na hora de se prever uma nova nota ou novo vinho quanto a qualidade. E, para prever o teor de alcóol dele, podemos usar o modelo de regressão linear múltipla que tem uma explicação do modelo de 0.7 aproximadamente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
